{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Running notebook using Python executable: /opt/anaconda3/envs/sb_analysis/bin/python\n",
      "DEBUG: Using Pandas version: 2.2.3\n",
      "\n",
      "Successfully loaded wiki_super_bowl_commercials_extracted.csv. Shape: (1345, 7)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Type</th>\n",
       "      <th>Advertiser_Product_Title</th>\n",
       "      <th>Title</th>\n",
       "      <th>Plot_Notes</th>\n",
       "      <th>Decade</th>\n",
       "      <th>Year</th>\n",
       "      <th>SuperBowlNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airlines</td>\n",
       "      <td>TWA \"Old West\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A contemporary TWA airliner lands in a wild we...</td>\n",
       "      <td>1960s</td>\n",
       "      <td>1969</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airlines</td>\n",
       "      <td>TWA \"Tour Our Tours\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotes the airliner's flights to Europe. Fea...</td>\n",
       "      <td>1960s</td>\n",
       "      <td>1969</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beer</td>\n",
       "      <td>Schlitz \"Comin' Atcha\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A man asks for a Schlitz beer at a bar. The ba...</td>\n",
       "      <td>1960s</td>\n",
       "      <td>1969</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>Chrysler \"Scuba Diver\"[6]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A scuba diver in a dreamy sequence with groovy...</td>\n",
       "      <td>1960s</td>\n",
       "      <td>1969</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Car</td>\n",
       "      <td>Plymouth \"Road Runner\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wile E. Coyote chases the Road Runner into a P...</td>\n",
       "      <td>1960s</td>\n",
       "      <td>1969</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product_Type   Advertiser_Product_Title Title  \\\n",
       "0     Airlines             TWA \"Old West\"   NaN   \n",
       "1     Airlines       TWA \"Tour Our Tours\"   NaN   \n",
       "2         Beer     Schlitz \"Comin' Atcha\"   NaN   \n",
       "3          Car  Chrysler \"Scuba Diver\"[6]   NaN   \n",
       "4          Car     Plymouth \"Road Runner\"   NaN   \n",
       "\n",
       "                                          Plot_Notes Decade  Year SuperBowlNum  \n",
       "0  A contemporary TWA airliner lands in a wild we...  1960s  1969          III  \n",
       "1  Promotes the airliner's flights to Europe. Fea...  1960s  1969          III  \n",
       "2  A man asks for a Schlitz beer at a bar. The ba...  1960s  1969          III  \n",
       "3  A scuba diver in a dreamy sequence with groovy...  1960s  1969          III  \n",
       "4  Wile E. Coyote chases the Road Runner into a P...  1960s  1969          III  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1345 entries, 0 to 1344\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Product_Type              1345 non-null   object\n",
      " 1   Advertiser_Product_Title  1343 non-null   object\n",
      " 2   Title                     509 non-null    object\n",
      " 3   Plot_Notes                1291 non-null   object\n",
      " 4   Decade                    1345 non-null   object\n",
      " 5   Year                      1345 non-null   int64 \n",
      " 6   SuperBowlNum              1345 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 73.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys # For checking python version/path inside notebook kernel if needed\n",
    "\n",
    "# Print environment info (good practice in notebooks too)\n",
    "print(f\"DEBUG: Running notebook using Python executable: {sys.executable}\")\n",
    "print(f\"DEBUG: Using Pandas version: {pd.__version__}\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define path relative to the project root\n",
    "# If your notebook is in notebooks/, use '../data/processed/'\n",
    "# If running as a script from src/, use '../data/processed/'\n",
    "# If running from project root, use 'data/processed/'\n",
    "PROCESSED_DIR = '../data/processed' # Adjust path if needed based on where notebook/script runs from\n",
    "FILENAME = 'wiki_super_bowl_commercials_extracted.csv'\n",
    "csv_path = os.path.join(PROCESSED_DIR, FILENAME)\n",
    "\n",
    "# --- Load the data ---\n",
    "try:\n",
    "    commercials_df = pd.read_csv(csv_path)\n",
    "    print(f\"\\nSuccessfully loaded {FILENAME}. Shape: {commercials_df.shape}\")\n",
    "\n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(commercials_df.head()) # display() often gives nicer output in notebooks\n",
    "\n",
    "    # Display basic info and data types\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    commercials_df.info()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at '{csv_path}'.\")\n",
    "    print(\"Please ensure the file exists and the PROCESSED_DIR path is correct relative to this notebook/script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading the CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entries in 'Advertiser_Product_Title': 1155\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique entries in 'Advertiser_Product_Title': {commercials_df['Advertiser_Product_Title'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 30 most frequent entries in 'Advertiser_Product_Title':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Advertiser_Product_Title\n",
       "T-Mobile                       20\n",
       "Bud Light                      11\n",
       "Squarespace                     8\n",
       "TurboTax                        8\n",
       "WeatherTech                     8\n",
       "NFL                             8\n",
       "Toyota                          7\n",
       "Doritos                         7\n",
       "Michelob Ultra                  7\n",
       "Budweiser                       7\n",
       "Pringles                        6\n",
       "Master Lock \"Marksman 2\"        5\n",
       "He Gets Us                      5\n",
       "Jeep                            5\n",
       "Tide                            5\n",
       "Booking.com                     4\n",
       "Tubi                            4\n",
       "Paramount+                      4\n",
       "Skechers                        4\n",
       "Uber Eats                       4\n",
       "Alfa Romeo                      3\n",
       "Johnson Controls \"LAX\"          3\n",
       "Homes.com                       3\n",
       "Verizon Wireless                3\n",
       "Sprint                          3\n",
       "Coca-Cola \"Hey Kid, Catch!\"     3\n",
       "Wix.com                         3\n",
       "Avocados From Mexico            3\n",
       "Disney+                         3\n",
       "Ram Trucks                      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nTop 30 most frequent entries in 'Advertiser_Product_Title':\")\n",
    "display(commercials_df['Advertiser_Product_Title'].value_counts().head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random samples of 'Year', 'Advertiser_Product_Title', and 'Title':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Advertiser_Product_Title</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1993</td>\n",
       "      <td>Honda Prelude \"Slingshot\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1990</td>\n",
       "      <td>Chrysler \"Lee Iacocca\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>2024</td>\n",
       "      <td>Wicked</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1987</td>\n",
       "      <td>Goodyear \"Lost Pet\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1988</td>\n",
       "      <td>Budweiser \"Rehab\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>2015</td>\n",
       "      <td>Minions</td>\n",
       "      <td>\"Super Fans\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>2016</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>\"4x4ever\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1984</td>\n",
       "      <td>Nationwide \"Puppy\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2024</td>\n",
       "      <td>Google Pixel 8</td>\n",
       "      <td>\"Javier in Frame\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1978</td>\n",
       "      <td>Gillette</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2007</td>\n",
       "      <td>Bud Light \"Hitchhiker\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1985</td>\n",
       "      <td>Johnson Controls \"Superdome\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2018</td>\n",
       "      <td>Kraft Foods</td>\n",
       "      <td>\"Family Greatly\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>2010</td>\n",
       "      <td>Volkswagen \"Punch Dub Days\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2001</td>\n",
       "      <td>Exit Wounds</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1972</td>\n",
       "      <td>Foundation for Full Service Banks \"Diner\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1998</td>\n",
       "      <td>NFL \"Anthony\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1981</td>\n",
       "      <td>Pabst Blue Ribbon \"Spirit\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>2023</td>\n",
       "      <td>Full Swing (Netflix)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1999</td>\n",
       "      <td>True Crime</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1978</td>\n",
       "      <td>Right Guard</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1972</td>\n",
       "      <td>ARCO \"A Little More Mileage\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2005</td>\n",
       "      <td>McDonald's \"Lincoln Fry\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>2003</td>\n",
       "      <td>Daredevil</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2004</td>\n",
       "      <td>AOL \"Slow Ride\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>2023</td>\n",
       "      <td>General Motors Netflix</td>\n",
       "      <td>\"Why not an EV?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>2021</td>\n",
       "      <td>T-Mobile</td>\n",
       "      <td>\"Family Drama\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>2018</td>\n",
       "      <td>Groupon</td>\n",
       "      <td>\"Who Wouldn't\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>2018</td>\n",
       "      <td>The Cloverfield Paradox (Netflix)</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2003</td>\n",
       "      <td>Sierra Mist \"Hydrant\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year                   Advertiser_Product_Title              Title\n",
       "286   1993                  Honda Prelude \"Slingshot\"                NaN\n",
       "261   1990                     Chrysler \"Lee Iacocca\"                NaN\n",
       "1222  2024                                     Wicked                NaN\n",
       "210   1987                        Goodyear \"Lost Pet\"                NaN\n",
       "221   1988                          Budweiser \"Rehab\"                NaN\n",
       "787   2015                                    Minions       \"Super Fans\"\n",
       "818   2016                                       Jeep          \"4x4ever\"\n",
       "163   1984                         Nationwide \"Puppy\"                NaN\n",
       "1255  2024                             Google Pixel 8  \"Javier in Frame\"\n",
       "76    1978                                   Gillette                NaN\n",
       "589   2007                     Bud Light \"Hitchhiker\"                NaN\n",
       "175   1985               Johnson Controls \"Superdome\"                NaN\n",
       "910   2018                                Kraft Foods   \"Family Greatly\"\n",
       "673   2010                Volkswagen \"Punch Dub Days\"                NaN\n",
       "430   2001                                Exit Wounds                NaN\n",
       "43    1972  Foundation for Full Service Banks \"Diner\"                NaN\n",
       "353   1998                              NFL \"Anthony\"                NaN\n",
       "115   1981                 Pabst Blue Ribbon \"Spirit\"                NaN\n",
       "1203  2023                       Full Swing (Netflix)                NaN\n",
       "374   1999                                 True Crime                NaN\n",
       "78    1978                                Right Guard                NaN\n",
       "49    1972               ARCO \"A Little More Mileage\"                NaN\n",
       "567   2005                   McDonald's \"Lincoln Fry\"                NaN\n",
       "481   2003                                  Daredevil                NaN\n",
       "528   2004                            AOL \"Slow Ride\"                NaN\n",
       "1149  2023                     General Motors Netflix   \"Why not an EV?\"\n",
       "1053  2021                                   T-Mobile     \"Family Drama\"\n",
       "922   2018                                    Groupon     \"Who Wouldn't\"\n",
       "903   2018          The Cloverfield Paradox (Netflix)                  —\n",
       "494   2003                      Sierra Mist \"Hydrant\"                NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nRandom samples of 'Year', 'Advertiser_Product_Title', and 'Title':\")\n",
    "# Show Year for context, Advertiser_Product_Title, and the separate Title column\n",
    "display(commercials_df[['Year', 'Advertiser_Product_Title', 'Title']].sample(30, random_state=42)) # random_state makes sample reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values in 'Advertiser_Product_Title': 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNumber of missing values in 'Advertiser_Product_Title': {commercials_df['Advertiser_Product_Title'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker mapping loaded successfully from '../data/raw/advertiser_ticker_mapping.csv'. Shape: (4, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BrandName</th>\n",
       "      <th>StockTicker</th>\n",
       "      <th>ParentCompany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budweiser</td>\n",
       "      <td>BUD</td>\n",
       "      <td>Anheuser-Busch InBev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pepsi</td>\n",
       "      <td>PEP</td>\n",
       "      <td>PepsiCo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Doritos</td>\n",
       "      <td>PEP</td>\n",
       "      <td>PepsiCo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda</td>\n",
       "      <td>HMC</td>\n",
       "      <td>Honda Motor Co.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BrandName StockTicker         ParentCompany\n",
       "0  Budweiser         BUD  Anheuser-Busch InBev\n",
       "1      Pepsi         PEP               PepsiCo\n",
       "2    Doritos         PEP               PepsiCo\n",
       "3      Honda         HMC       Honda Motor Co."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 4 unique known brands for matching (longest first):\n",
      "['budweiser', 'doritos', 'pepsi', 'honda'] ...\n"
     ]
    }
   ],
   "source": [
    "# In a new cell in your notebook\n",
    "import pandas as pd\n",
    "import numpy as np # For handling potential missing tickers later\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "TICKER_MAP_FILENAME = 'advertiser_ticker_mapping.csv'\n",
    "RAW_DATA_DIR = '../data/raw' # Adjust path if needed\n",
    "ticker_map_path = os.path.join(RAW_DATA_DIR, TICKER_MAP_FILENAME)\n",
    "\n",
    "# --- Load Ticker Map ---\n",
    "try:\n",
    "    ticker_map_df = pd.read_csv(ticker_map_path)\n",
    "    print(f\"Ticker mapping loaded successfully from '{ticker_map_path}'. Shape: {ticker_map_df.shape}\")\n",
    "    display(ticker_map_df.head())\n",
    "\n",
    "    # Create a set of known brand names (lowercase) for faster lookups\n",
    "    known_brands_set = set(ticker_map_df['BrandName'].dropna().str.lower())\n",
    "    # Create a list sorted by length descending (important for matching longer names first)\n",
    "    known_brands_sorted = sorted(list(known_brands_set), key=len, reverse=True)\n",
    "\n",
    "    print(f\"\\nLoaded {len(known_brands_sorted)} unique known brands for matching (longest first):\")\n",
    "    print(known_brands_sorted[:10], \"...\") # Print first 10\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Ticker mapping file not found at '{ticker_map_path}'\")\n",
    "    print(\"Please create this file with columns: BrandName, StockTicker, ParentCompany\")\n",
    "    known_brands_sorted = [] # Set empty list so subsequent cells don't fail immediately\n",
    "    ticker_map_df = pd.DataFrame() # Create empty df\n",
    "except Exception as e:\n",
    "     print(f\"Error loading or processing ticker map: {e}\")\n",
    "     known_brands_sorted = []\n",
    "     ticker_map_df = pd.DataFrame()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'get_primary_advertiser' defined.\n"
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "def get_primary_advertiser(adv_prod_title, brands_sorted_list, brand_map_df):\n",
    "    \"\"\"\n",
    "    Extracts primary advertiser based on matching known brands (longest first)\n",
    "    within the adv_prod_title string.\n",
    "    Returns the canonical brand name from the map.\n",
    "    \"\"\"\n",
    "    # Ensure input is treated as string, handle potential NaN values\n",
    "    if pd.isna(adv_prod_title):\n",
    "        return None\n",
    "    text_to_search = str(adv_prod_title).lower()\n",
    "\n",
    "    match_found = None\n",
    "\n",
    "    # Check for known brands within the string, starting with longest names\n",
    "    for brand_lower in brands_sorted_list:\n",
    "        # Basic substring check - first match (longest) wins\n",
    "        if brand_lower in text_to_search:\n",
    "             match_found = brand_lower\n",
    "             break # Take the first (longest) match found\n",
    "\n",
    "    # If a known brand substring was found\n",
    "    if match_found:\n",
    "         # Find the original casing/canonical name from the map dataframe\n",
    "         try:\n",
    "             if not brand_map_df.empty:\n",
    "                # Find the row using boolean indexing, get the BrandName column, extract first value\n",
    "                original_case_brand = brand_map_df.loc[brand_map_df['BrandName'].str.lower() == match_found, 'BrandName'].iloc[0]\n",
    "                return original_case_brand\n",
    "             else:\n",
    "                 return None # Cannot find original case if map is empty\n",
    "         except (IndexError, KeyError):\n",
    "              # Safety check in case lookup fails unexpectedly\n",
    "              print(f\"Warning: Could not find original casing for matched brand '{match_found}' in map.\")\n",
    "              return None\n",
    "    else:\n",
    "        # No known brand found directly within the string\n",
    "        return None # Indicates no known primary brand was identified\n",
    "\n",
    "print(\"Function 'get_primary_advertiser' defined.\") # Confirmation message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying extraction function to 'Advertiser_Product_Title'...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ld/_7vnbqnn3_z5r7s10zfqclx00000gn/T/ipykernel_92898/1086258889.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'commercials_df'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'known_brands_sorted'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mknown_brands_sorted\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'ticker_map_df'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mticker_map_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Applying extraction function to 'Advertiser_Product_Title'...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Apply the function to the column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     commercials_df['Primary_Advertiser'] = commercials_df.apply(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_primary_advertiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_brands_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker_map_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# Apply function row-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n",
      "\u001b[0;32m/opt/anaconda3/envs/sb_analysis/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10370\u001b[0m             \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10371\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/sb_analysis/lib/python3.10/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;31m# raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/sb_analysis/lib/python3.10/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/sb_analysis/lib/python3.10/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                     \u001b[0;31m#  series_generator will swap out the underlying data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ld/_7vnbqnn3_z5r7s10zfqclx00000gn/T/ipykernel_92898/1086258889.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_primary_advertiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_brands_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker_map_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/ld/_7vnbqnn3_z5r7s10zfqclx00000gn/T/ipykernel_92898/2996249369.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(adv_prod_title, brands_sorted_list, brand_map_df)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwithin\u001b[0m \u001b[0mthe\u001b[0m \u001b[0madv_prod_title\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcanonical\u001b[0m \u001b[0mbrand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Ensure input is treated as string, handle potential NaN values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_prod_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtext_to_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_prod_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/sb_analysis/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "# Check if variables exist before proceeding\n",
    "if 'commercials_df' in locals() and 'known_brands_sorted' in locals() and known_brands_sorted and 'ticker_map_df' in locals() and not ticker_map_df.empty:\n",
    "    print(\"Applying extraction function to 'Advertiser_Product_Title'...\")\n",
    "\n",
    "    # Apply the function to the column\n",
    "    commercials_df['Primary_Advertiser'] = commercials_df.apply(\n",
    "        lambda row: get_primary_advertiser(row, known_brands_sorted, ticker_map_df),\n",
    "        axis=1 # Apply function row-wise\n",
    "    )\n",
    "    # --- Alternatively, if function only needs the single column value: ---\n",
    "    # commercials_df['Primary_Advertiser'] = commercials_df['Advertiser_Product_Title'].apply(\n",
    "    #    lambda x: get_primary_advertiser(x, known_brands_sorted, ticker_map_df)\n",
    "    # )\n",
    "    # Let's stick with the row apply for now as it allows access to 'Title' if needed later\n",
    "\n",
    "    print(\"Extraction function applied.\")\n",
    "\n",
    "    # --- Inspect the results ---\n",
    "    print(\"\\nPreview of extraction results (showing relevant columns):\")\n",
    "    display(commercials_df[['Year', 'Advertiser_Product_Title', 'Title', 'Primary_Advertiser']].head(10))\n",
    "\n",
    "    print(\"\\nValue counts for extracted 'Primary_Advertiser':\")\n",
    "    display(commercials_df['Primary_Advertiser'].value_counts().head(30)) # Show more counts\n",
    "\n",
    "    null_count = commercials_df['Primary_Advertiser'].isnull().sum()\n",
    "    total_count = len(commercials_df)\n",
    "    print(f\"\\nNumber of commercials where Primary_Advertiser could NOT be extracted: {null_count} out of {total_count}\")\n",
    "\n",
    "    print(\"\\nExamples of extraction failures (Primary_Advertiser is Null):\")\n",
    "    display(commercials_df[commercials_df['Primary_Advertiser'].isnull()][['Year', 'Advertiser_Product_Title', 'Title']].head(20))\n",
    "\n",
    "else:\n",
    "    print(\"Make sure 'commercials_df' is loaded and the ticker mapping ('known_brands_sorted', 'ticker_map_df') was processed successfully and is not empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG Function 'get_primary_advertiser_debug1' defined.\n"
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "# DEBUG version 1: Returns lowercase match directly\n",
    "\n",
    "def get_primary_advertiser_debug1(adv_prod_title, brands_sorted_list): # Removed brand_map_df argument for this test\n",
    "    \"\"\"\n",
    "    DEBUGGING: Attempts to extract a known brand name, returns lowercase match directly.\n",
    "    \"\"\"\n",
    "    if pd.isna(adv_prod_title):\n",
    "        return None\n",
    "    text_to_search = str(adv_prod_title).lower()\n",
    "    match_found = None\n",
    "\n",
    "    # Check for known brands within the string, starting with longest names\n",
    "    for brand_lower in brands_sorted_list:\n",
    "        if brand_lower in text_to_search:\n",
    "             match_found = brand_lower\n",
    "             break # Take the first (longest) match found\n",
    "\n",
    "    # --- MODIFIED: Return lowercase match directly, skip lookup ---\n",
    "    return match_found\n",
    "\n",
    "print(\"DEBUG Function 'get_primary_advertiser_debug1' defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying DEBUG extraction function (returning lowercase match)...\n",
      "DEBUG function 1 applied successfully.\n",
      "\n",
      "Preview of Debug1 results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Advertiser_Product_Title</th>\n",
       "      <th>Primary_Advertiser_Debug1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TWA \"Old West\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TWA \"Tour Our Tours\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schlitz \"Comin' Atcha\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chrysler \"Scuba Diver\"[6]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plymouth \"Road Runner\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pall Mall \"Gold\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Silva Thins \"Lower Tar\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salem \"Country\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Winston \"Playing Your Song\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RCA \"Non-Smear Color #1\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Advertiser_Product_Title Primary_Advertiser_Debug1\n",
       "0               TWA \"Old West\"                      None\n",
       "1         TWA \"Tour Our Tours\"                      None\n",
       "2       Schlitz \"Comin' Atcha\"                      None\n",
       "3    Chrysler \"Scuba Diver\"[6]                      None\n",
       "4       Plymouth \"Road Runner\"                      None\n",
       "5             Pall Mall \"Gold\"                      None\n",
       "6      Silva Thins \"Lower Tar\"                      None\n",
       "7              Salem \"Country\"                      None\n",
       "8  Winston \"Playing Your Song\"                      None\n",
       "9     RCA \"Non-Smear Color #1\"                      None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for Debug1 extracted advertisers:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Primary_Advertiser_Debug1\n",
       "budweiser    53\n",
       "pepsi        33\n",
       "doritos      23\n",
       "honda         8\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of commercials where Primary_Advertiser_Debug1 could NOT be extracted: 1228\n"
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "# Check if variables exist before proceeding\n",
    "if 'commercials_df' in locals() and 'known_brands_sorted' in locals() and known_brands_sorted:\n",
    "    print(\"Applying DEBUG extraction function (returning lowercase match)...\")\n",
    "\n",
    "    try:\n",
    "        # Apply the MODIFIED function (Note: lambda now calls debug1 and doesn't need brand_map_df)\n",
    "        commercials_df['Primary_Advertiser_Debug1'] = commercials_df.apply(\n",
    "            lambda row: get_primary_advertiser_debug1(row['Advertiser_Product_Title'], known_brands_sorted),\n",
    "            axis=1\n",
    "        )\n",
    "        print(\"DEBUG function 1 applied successfully.\")\n",
    "\n",
    "        # --- Inspect the results ---\n",
    "        print(\"\\nPreview of Debug1 results:\")\n",
    "        display(commercials_df[['Advertiser_Product_Title', 'Primary_Advertiser_Debug1']].head(10))\n",
    "\n",
    "        print(\"\\nValue counts for Debug1 extracted advertisers:\")\n",
    "        display(commercials_df['Primary_Advertiser_Debug1'].value_counts().head(20))\n",
    "\n",
    "        null_count = commercials_df['Primary_Advertiser_Debug1'].isnull().sum()\n",
    "        print(f\"\\nNumber of commercials where Primary_Advertiser_Debug1 could NOT be extracted: {null_count}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "         print(f\"\\nDEBUG FAILED: Caught ValueError during apply: {e}\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\nDEBUG FAILED: Caught unexpected error during apply: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Make sure 'commercials_df' is loaded and 'known_brands_sorted' exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading or processing ticker map: Error tokenizing data. C error: Expected 3 fields in line 34, saw 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In the cell where you load the ticker map (replace previous content)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "TICKER_MAP_FILENAME = 'advertiser_ticker_mapping.csv'\n",
    "RAW_DATA_DIR = '../data/raw' # Adjust path if needed\n",
    "ticker_map_path = os.path.join(RAW_DATA_DIR, TICKER_MAP_FILENAME)\n",
    "\n",
    "# --- Initialize variables ---\n",
    "ticker_map_df = pd.DataFrame()\n",
    "original_case_map = {}\n",
    "known_brands_sorted = []\n",
    "\n",
    "# --- Load Ticker Map ---\n",
    "try:\n",
    "    ticker_map_df = pd.read_csv(ticker_map_path)\n",
    "    print(f\"Ticker mapping loaded successfully from '{ticker_map_path}'. Shape: {ticker_map_df.shape}\")\n",
    "    # display(ticker_map_df.head()) # Optional\n",
    "\n",
    "    # --- Create Lookup Dictionary and Sorted List (Corrected Logic) ---\n",
    "    if not ticker_map_df.empty and 'BrandName' in ticker_map_df.columns and ticker_map_df['BrandName'].notna().any():\n",
    "        # Create lowercase Series, dropping rows where original BrandName is NaN first\n",
    "        lc_brands = ticker_map_df.dropna(subset=['BrandName'])['BrandName'].str.lower()\n",
    "        # Get index of first occurrence of each unique lowercase brand\n",
    "        unique_lc_indices = lc_brands.drop_duplicates(keep='first').index\n",
    "        # Select the corresponding rows from the original DataFrame using these valid indices\n",
    "        lc_map_temp = ticker_map_df.loc[unique_lc_indices]\n",
    "\n",
    "        # Create dictionary mapping: lowercase brand name -> original BrandName casing\n",
    "        # Ensure index is unique before creating Series (should be guaranteed by drop_duplicates)\n",
    "        original_case_map = pd.Series(\n",
    "            lc_map_temp.BrandName.values,\n",
    "            index=lc_map_temp.BrandName.str.lower() # Index is unique lowercase\n",
    "        ).to_dict()\n",
    "\n",
    "        # Create a sorted list of unique lowercase brands for matching function\n",
    "        known_brands_set = set(original_case_map.keys()) # Use keys from dict for consistency\n",
    "        known_brands_sorted = sorted(list(known_brands_set), key=len, reverse=True)\n",
    "\n",
    "        print(\"\\nCreated lookup dictionary and sorted brand list.\")\n",
    "        print(f\"Total unique lowercase brands found: {len(known_brands_sorted)}\")\n",
    "        print(\"Sample lookup map:\", dict(list(original_case_map.items())[:5]))\n",
    "        print(\"Sample sorted brands:\", known_brands_sorted[:5], \"...\")\n",
    "\n",
    "    else:\n",
    "        print(\"Ticker map DataFrame ('ticker_map_df') is empty or missing 'BrandName' column or has no valid BrandNames.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Ticker mapping file not found at '{ticker_map_path}'\")\n",
    "    # Keep variables initialized as empty\n",
    "except Exception as e:\n",
    "     print(f\"Error loading or processing ticker map: {e}\")\n",
    "     # Keep variables initialized as empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final function 'get_primary_advertiser_final' defined.\n"
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "def get_primary_advertiser_final(adv_prod_title, brands_sorted_list, lc_to_orig_map):\n",
    "    \"\"\"\n",
    "    Extracts primary advertiser based on matching known brands (longest first)\n",
    "    within the adv_prod_title string. Uses a dictionary lookup for original casing.\n",
    "    Returns the canonical brand name from the map or None.\n",
    "    \"\"\"\n",
    "    if pd.isna(adv_prod_title):\n",
    "        return None\n",
    "    text_to_search = str(adv_prod_title).lower()\n",
    "    match_found_lc = None # The matched brand will be lowercase\n",
    "\n",
    "    # Check for known brands within the string, starting with longest names\n",
    "    for brand_lower in brands_sorted_list:\n",
    "        if brand_lower in text_to_search:\n",
    "             match_found_lc = brand_lower\n",
    "             break # Take the first (longest) match found\n",
    "\n",
    "    # If a known brand substring was found (it will be lowercase)\n",
    "    if match_found_lc:\n",
    "         # Lookup original case in the pre-built dictionary using .get() for safety\n",
    "         original_case_brand = lc_to_orig_map.get(match_found_lc)\n",
    "         return original_case_brand # Returns original case or None if not in map (shouldn't happen)\n",
    "    else:\n",
    "        # No known brand found directly within the string\n",
    "        return None\n",
    "\n",
    "print(\"Final function 'get_primary_advertiser_final' defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure 'commercials_df' is loaded and the ticker mapping ('known_brands_sorted', 'original_case_map') was processed successfully and is not empty.\n"
     ]
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "# Check if variables exist before proceeding\n",
    "if 'commercials_df' in locals() and 'known_brands_sorted' in locals() and known_brands_sorted and 'original_case_map' in locals() and original_case_map:\n",
    "    print(\"Applying FINAL extraction function to 'Advertiser_Product_Title'...\")\n",
    "\n",
    "    # Apply directly to the Series, passing extra args via 'args' tuple\n",
    "    commercials_df['Primary_Advertiser'] = commercials_df['Advertiser_Product_Title'].apply(\n",
    "        get_primary_advertiser_final, # Pass the function name\n",
    "        args=(known_brands_sorted, original_case_map) # Pass other args needed by function\n",
    "    )\n",
    "\n",
    "    print(\"FINAL extraction function applied.\")\n",
    "\n",
    "    # --- Inspect the results ---\n",
    "    print(\"\\nPreview of FINAL extraction results:\")\n",
    "    display(commercials_df[['Year', 'Advertiser_Product_Title', 'Title', 'Primary_Advertiser']].head(10))\n",
    "\n",
    "    print(\"\\nValue counts for extracted 'Primary_Advertiser':\")\n",
    "    display(commercials_df['Primary_Advertiser'].value_counts().head(30))\n",
    "\n",
    "    null_count = commercials_df['Primary_Advertiser'].isnull().sum()\n",
    "    total_count = len(commercials_df)\n",
    "    print(f\"\\nNumber of commercials where Primary_Advertiser could NOT be extracted: {null_count} out of {total_count}\")\n",
    "\n",
    "    print(\"\\nExamples of extraction failures (Primary_Advertiser is Null):\")\n",
    "    display(commercials_df[commercials_df['Primary_Advertiser'].isnull()][['Year', 'Advertiser_Product_Title', 'Title']].head(20))\n",
    "\n",
    "else:\n",
    "    print(\"Make sure 'commercials_df' is loaded and the ticker mapping ('known_brands_sorted', 'original_case_map') was processed successfully and is not empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary_Advertiser\n",
       "Budweiser         53\n",
       "Pepsi             33\n",
       "Doritos           23\n",
       "McDonald's        19\n",
       "Coca-Cola         12\n",
       "Ford              10\n",
       "Gillette           9\n",
       "Chrysler           8\n",
       "Goodyear           8\n",
       "Honda              8\n",
       "Netflix            4\n",
       "General Motors     3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commercials_df['Primary_Advertiser'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 969 rows with unmapped advertisers.\n",
      "Found 899 unique 'Advertiser_Product_Title' strings to research.\n",
      "\n",
      "Most frequent unmapped 'Advertiser_Product_Title' entries:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Advertiser_Product_Title\n",
       "NFL                           8\n",
       "WeatherTech                   8\n",
       "He Gets Us                    5\n",
       "Alfa Romeo                    3\n",
       "Homes.com                     3\n",
       "Wix.com                       3\n",
       "Sprint                        3\n",
       "Avocados From Mexico          3\n",
       "Ram Trucks                    3\n",
       "Verizon Wireless              3\n",
       "Agentforce by Salesforce      2\n",
       "Lay's                         2\n",
       "M&M's                         2\n",
       "Stella Artois                 2\n",
       "Turkish Airlines              2\n",
       "Xerox \"Monks\"                 2\n",
       "Planters                      2\n",
       "Xfinity                       2\n",
       "Coors Light                   2\n",
       "Poppi                         2\n",
       "Pfizer                        2\n",
       "FanDuel                       2\n",
       "Canon \"Joe Theismann\"         2\n",
       "Nerds Gummy Clusters          2\n",
       "Hellmann's/Best Foods         2\n",
       "EF Hutton \"Joggers\"           2\n",
       "Dunkin' Donuts                2\n",
       "DoorDash                      2\n",
       "Dove                          2\n",
       "Masterlock \"Lock Abuse\"       2\n",
       "homes.com                     2\n",
       "F9                            2\n",
       "2025 IndyCar Series (Fox)     2\n",
       "U.S. Marines \"Sword\"          2\n",
       "Rakuten                       2\n",
       "Rocket Mortgage               2\n",
       "BMW                           2\n",
       "E-Trade                       2\n",
       "Esurance                      2\n",
       "Avocados from Mexico          2\n",
       "2018 Winter Olympics (NBC)    2\n",
       "Skittles                      2\n",
       "Nationwide                    2\n",
       "DraftKings                    2\n",
       "e.l.f.                        2\n",
       "Taco Bell                     2\n",
       "Ray-Ban Meta                  2\n",
       "Dollar Shave Club             1\n",
       "The Pokémon Company           1\n",
       "Schick                        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "# Check if Primary_Advertiser column exists\n",
    "if 'commercials_df' in locals() and 'Primary_Advertiser' in commercials_df.columns:\n",
    "    # Filter rows where the extraction failed (Primary_Advertiser is null)\n",
    "    unmapped_df = commercials_df[commercials_df['Primary_Advertiser'].isnull()].copy()\n",
    "\n",
    "    print(f\"Found {len(unmapped_df)} rows with unmapped advertisers.\")\n",
    "\n",
    "    # Get the unique values from the original column for these unmapped rows\n",
    "    unique_unmapped_titles = unmapped_df['Advertiser_Product_Title'].unique()\n",
    "    print(f\"Found {len(unique_unmapped_titles)} unique 'Advertiser_Product_Title' strings to research.\")\n",
    "\n",
    "    # --- Optional: Prioritize by Frequency ---\n",
    "    # Get value counts for the unmapped original titles to see which appear most often\n",
    "    print(\"\\nMost frequent unmapped 'Advertiser_Product_Title' entries:\")\n",
    "    unmapped_counts = unmapped_df['Advertiser_Product_Title'].value_counts()\n",
    "    display(unmapped_counts.head(50)) # Show top 50 frequencies\n",
    "\n",
    "    # --- Optional: Save this list to work from ---\n",
    "    # research_list_path = '../data/raw/research_needed_advertisers.txt'\n",
    "    # unmapped_counts.index.to_series().to_csv(research_list_path, index=False, header=False)\n",
    "    # print(f\"\\nFull list of unique unmapped entries saved to: {research_list_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"Ensure 'commercials_df' is loaded and 'Primary_Advertiser' column was created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the remaining 969 unmapped rows...\n",
      "\n",
      "Top 50 most frequent 'Advertiser_Product_Title' entries among UNMAPPED rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Advertiser_Product_Title\n",
       "NFL                           8\n",
       "WeatherTech                   8\n",
       "He Gets Us                    5\n",
       "Alfa Romeo                    3\n",
       "Homes.com                     3\n",
       "Wix.com                       3\n",
       "Sprint                        3\n",
       "Avocados From Mexico          3\n",
       "Ram Trucks                    3\n",
       "Verizon Wireless              3\n",
       "Agentforce by Salesforce      2\n",
       "Lay's                         2\n",
       "M&M's                         2\n",
       "Stella Artois                 2\n",
       "Turkish Airlines              2\n",
       "Xerox \"Monks\"                 2\n",
       "Planters                      2\n",
       "Xfinity                       2\n",
       "Coors Light                   2\n",
       "Poppi                         2\n",
       "Pfizer                        2\n",
       "FanDuel                       2\n",
       "Canon \"Joe Theismann\"         2\n",
       "Nerds Gummy Clusters          2\n",
       "Hellmann's/Best Foods         2\n",
       "EF Hutton \"Joggers\"           2\n",
       "Dunkin' Donuts                2\n",
       "DoorDash                      2\n",
       "Dove                          2\n",
       "Masterlock \"Lock Abuse\"       2\n",
       "homes.com                     2\n",
       "F9                            2\n",
       "2025 IndyCar Series (Fox)     2\n",
       "U.S. Marines \"Sword\"          2\n",
       "Rakuten                       2\n",
       "Rocket Mortgage               2\n",
       "BMW                           2\n",
       "E-Trade                       2\n",
       "Esurance                      2\n",
       "Avocados from Mexico          2\n",
       "2018 Winter Olympics (NBC)    2\n",
       "Skittles                      2\n",
       "Nationwide                    2\n",
       "DraftKings                    2\n",
       "e.l.f.                        2\n",
       "Taco Bell                     2\n",
       "Ray-Ban Meta                  2\n",
       "Dollar Shave Club             1\n",
       "The Pokémon Company           1\n",
       "Schick                        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In a new cell\n",
    "\n",
    "# Make sure commercials_df exists and has the 'Primary_Advertiser' column\n",
    "if 'commercials_df' in locals() and 'Primary_Advertiser' in commercials_df.columns:\n",
    "    # Create a temporary DataFrame of only the rows that ARE STILL NULL after mapping\n",
    "    unmapped_subset = commercials_df[commercials_df['Primary_Advertiser'].isnull()].copy()\n",
    "\n",
    "    print(f\"Analyzing the remaining {len(unmapped_subset)} unmapped rows...\")\n",
    "\n",
    "    if not unmapped_subset.empty:\n",
    "        print(\"\\nTop 50 most frequent 'Advertiser_Product_Title' entries among UNMAPPED rows:\")\n",
    "        # Show the most common unmapped strings\n",
    "        display(unmapped_subset['Advertiser_Product_Title'].value_counts().head(50))\n",
    "\n",
    "        # Optional: You could also check product types for these unmapped ones\n",
    "        # print(\"\\nTop Product Types among UNMAPPED rows:\")\n",
    "        # display(unmapped_subset['Product_Type'].value_counts().head(20))\n",
    "    else:\n",
    "        # This shouldn't happen if the previous null count was > 0\n",
    "        print(\"No unmapped rows found (this is unexpected based on previous count).\")\n",
    "else:\n",
    "    print(\"Ensure 'commercials_df' is loaded and 'Primary_Advertiser' column exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
